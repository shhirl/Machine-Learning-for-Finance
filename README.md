# Bayesian Framework for Gaussian Process Variable Selection 
Machine-Learning-for-Finance <br/>
Term 3 Module during MSc Data Science


1. Introduction<br/>
The typical method for variable selection when implementing Gaussian process models is automatic relevance determination (ARD). In this project I follow the paper by Paananen et al, to implement two variable selection methods that are proposed for Gaussian process models via sensitivity analysis of the posterior predictive distribution. I implement and reproduce their empirical results on synthetic data to show an improvement in variable selection compared to automatic relevant determination. I also explore other alternatives for ARD in the literature.

2. Background<br/>
2.1 Gaussian Processes and Automatic Relevance Determination<br/>
2.2 Kullback-Leibler Divergence as a Measure of Predictive Performance (KL Method)<br/>
2.3 Variance of the Posterior Latent Mean<br/>

3. Synthetic Data Experiments<br/>

4. Conclusion
